# üèóÔ∏è SOC Pipeline Architecture - Detailed Technical Documentation

**Project:** AI-Powered Alert Prioritization for Wazuh  
**Version:** 1.0  
**Date:** 2025-01-XX  
**Perspective:** SOC Technical Architecture

---

## üìã TABLE OF CONTENTS

1. [Executive Summary](#executive-summary)
2. [Pipeline Architecture Overview](#pipeline-architecture-overview)
3. [Module-by-Module Architecture](#module-by-module-architecture)
4. [Data Flow & State Management](#data-flow--state-management)
5. [Error Handling & Resilience](#error-handling--resilience)
6. [Performance & Scalability](#performance--scalability)
7. [Configuration Management](#configuration-management)
8. [Dependencies & Integration Points](#dependencies--integration-points)

---

## üéØ EXECUTIVE SUMMARY

Pipeline n√†y l√† m·ªôt **single-threaded, event-driven loop** ch·∫°y tr√™n m·ªôt m√°y (c√≥ th·ªÉ scale horizontal b·∫±ng c√°ch ch·∫°y nhi·ªÅu instance v·ªõi cursor ri√™ng). Pipeline ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ:

- **Kh√¥ng b·ªè s√≥t c·∫£nh b√°o quan tr·ªçng**: SOC two-tier filtering + critical override
- **Resilient**: Retry logic, fallback messages, graceful degradation
- **Observable**: Structured logging v·ªõi context (component, action, rule_id, agent_id)
- **Configurable**: T·∫•t c·∫£ thresholds v√† behavior ƒëi·ªÅu khi·ªÉn qua environment variables

---

## üîÑ PIPELINE ARCHITECTURE OVERVIEW

### High-Level Pipeline Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MAIN LOOP (run_pipeline.py)                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  while True:                                                    ‚îÇ
‚îÇ    1. Poll Wazuh Indexer (fetch_alerts)                       ‚îÇ
‚îÇ    2. For each alert:                                          ‚îÇ
‚îÇ       a. Normalize ‚Üí AlertNormalized                            ‚îÇ
‚îÇ       b. Enrich (GeoIP, Threat Intel)                          ‚îÇ
‚îÇ       c. Correlate (group related alerts)                      ‚îÇ
‚îÇ       d. FP Filtering (label, don't drop)                     ‚îÇ
‚îÇ       e. Triage (heuristic + LLM)                              ‚îÇ
‚îÇ       f. Notify (Telegram if score >= threshold OR critical)   ‚îÇ
‚îÇ    3. Save cursor state                                        ‚îÇ
‚îÇ    4. Sleep (poll_interval)                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Module Organization

```
src/
‚îú‚îÄ‚îÄ collector/          # Data ingestion layer
‚îÇ   ‚îî‚îÄ‚îÄ wazuh_client.py    # Wazuh Indexer client, SOC two-tier filtering, normalization
‚îÇ
‚îú‚îÄ‚îÄ analyzer/           # Analysis layer
‚îÇ   ‚îú‚îÄ‚îÄ heuristic.py       # Rule-based scoring (rule.level, groups, MITRE, flow stats)
‚îÇ   ‚îú‚îÄ‚îÄ llm.py            # LLM-based analysis (OpenAI API, caching, anti-hallucination)
‚îÇ   ‚îî‚îÄ‚îÄ triage.py         # Fusion logic (heuristic + LLM, dynamic weighting, threat adjustment)
‚îÇ
‚îú‚îÄ‚îÄ orchestrator/       # Orchestration layer
‚îÇ   ‚îî‚îÄ‚îÄ notify.py          # Telegram notification, critical override, message formatting
‚îÇ
‚îî‚îÄ‚îÄ common/             # Shared utilities
    ‚îú‚îÄ‚îÄ config.py          # Environment variable loading & validation
    ‚îú‚îÄ‚îÄ correlation.py     # Alert correlation engine (in-memory groups)
    ‚îú‚îÄ‚îÄ dedup.py          # Deduplication key generation
    ‚îú‚îÄ‚îÄ enrichment.py     # GeoIP, Threat Intel enrichment
    ‚îú‚îÄ‚îÄ fp_filtering.py   # False positive labeling (no silent drops)
    ‚îú‚îÄ‚îÄ llm_cache.py      # LLM result caching (LRU, TTL)
    ‚îú‚îÄ‚îÄ logging.py        # Structured logging setup
    ‚îú‚îÄ‚îÄ redaction.py      # PII redaction for LLM
    ‚îú‚îÄ‚îÄ timezone.py       # Timezone handling
    ‚îî‚îÄ‚îÄ web.py            # RetrySession (HTTP client with retry logic)
```

---

## üß© MODULE-BY-MODULE ARCHITECTURE

### 1. Collector Module (`src/collector/wazuh_client.py`)

**Responsibility**: Thu th·∫≠p alerts t·ª´ Wazuh Indexer, √°p d·ª•ng SOC two-tier filtering, chu·∫©n h√≥a th√†nh AlertNormalized.

#### 1.1 Class: `WazuhClient`

**Initialization**:
```python
def __init__(self):
    # Setup API session (Wazuh Manager API - optional, mainly for token refresh)
    self.session = RetrySession()
    self._setup_api_session()  # Bearer token or Basic auth
    
    # Setup indexer session (OpenSearch/Wazuh Indexer - REQUIRED)
    self.indexer_session = RetrySession()
    self._setup_indexer_session()  # Basic auth (WAZUH_INDEXER_USER/PASS)
    
    # SSL verification: True/False or path to cert file
    # Logs warning if SSL disabled (security risk)
```

**Key Methods**:

- **`fetch_alerts()` ‚Üí `List[Dict[str, Any]]`**
  - **Purpose**: Main entry point ƒë·ªÉ l·∫•y alerts t·ª´ indexer
  - **Logic**:
    1. Load cursor t·ª´ file (`CURSOR_PATH`, default `/app/state/cursor.json`)
    2. T√≠nh to√°n lookback window:
       - **Realtime mode** (`WAZUH_DEMO_MODE` ho·∫∑c `WAZUH_START_FROM_NOW`):
         - Lookback = `WAZUH_POLL_INTERVAL_SEC + INDEXER_DELAY_SECONDS + buffer`
         - Cutoff = `now - lookback`
       - **Normal mode**:
         - N·∫øu c√≥ cursor: `max(cursor.timestamp - INDEXER_DELAY_SECONDS, now - 24h)`
         - N·∫øu kh√¥ng c√≥ cursor: `now - 24h - INDEXER_DELAY_SECONDS`
    3. **Agent-balanced fetching** (n·∫øu `expected_agents` ƒë∆∞·ª£c set):
       - Loop qua t·ª´ng agent (001, 002, ...)
       - G·ªçi `_fetch_alerts_for_agent(agent_id, cursor, page_size=100)`
       - Merge k·∫øt qu·∫£ t·ª´ t·∫•t c·∫£ agents
    4. **SOC two-tier filtering** (trong `_build_indexer_query`):
       - **Tier 1**: `rule.level` trong [MIN_LEVEL..MAX_LEVEL] **AND** (`rule.id` trong INCLUDE_RULE_IDS **OR** `rule.id` b·∫Øt ƒë·∫ßu v·ªõi INCLUDE_RULE_ID_PREFIX)
       - **Tier 2**: `rule.level >= ALWAYS_REEVALUATE_LEVEL_GTE` (m·∫∑c ƒë·ªãnh 7)
       - Query d√πng `bool.should` v·ªõi `minimum_should_match=1` ‚Üí m·ªôt trong hai tier pass l√† ƒë∆∞·ª£c
    5. Sort: `@timestamp ASC`, `agent.id ASC`, `_id ASC` (ƒë·ªÉ ph√¢n ph·ªëi ƒë·ªÅu agents)
    6. Pagination: `search_after` n·∫øu c√≥ cursor.sort (ch√≠nh x√°c h∆°n timestamp-based)
    7. Normalize t·ª´ng alert: `_normalize_alert(hit["_source"])`
    8. Update cursor: `{"timestamp": last_alert_timestamp, "sort": [timestamp, agent_id, _id]}`
    9. Save cursor: `_save_cursor(cursor)`
  - **Returns**: List of AlertNormalized dictionaries
  - **Error Handling**: 
    - N·∫øu indexer kh√¥ng reachable ‚Üí log error, return empty list (kh√¥ng crash pipeline)
    - N·∫øu query syntax error ‚Üí log error, return empty list

- **`_normalize_alert(raw: Dict) ‚Üí AlertNormalized`**
  - **Purpose**: Chu·∫©n h√≥a raw Wazuh alert th√†nh c·∫•u tr√∫c th·ªëng nh·∫•t
  - **Input**: Raw `_source` t·ª´ OpenSearch hit
  - **Output**: AlertNormalized dict v·ªõi c√°c field:
    - **Timestamps**: `@timestamp` (UTC ISO), `@timestamp_local` (localized)
    - **Identity**: `event_id` (`_id`), `index`, `agent.{id,name,ip}`, `manager.name`, `decoder.name`, `location`
    - **Rule**: `rule.{id,level,description,groups,mitre,firedtimes}`
    - **Network**: `src_ip`, `dest_ip`, `src_port`, `dest_port`, `proto`, `app_proto`, `direction`, `in_iface`, `flow_id`, `tx_id`
    - **Flow stats**: `flow.{pkts_toserver,pkts_toclient,bytes_toserver,bytes_toclient,start}`
    - **HTTP context**: `http.{method,url,status,hostname,user_agent,referer,redirect}`, `http_anomaly_count`
    - **Suricata alert**: `suricata_alert.{signature_id,signature,category,action,severity}`
    - **Tags**: Derived t·ª´ `rule.groups`, `suricata.category`, signature keywords
    - **Raw data**: `full_data` (copy c·ªßa `data.*`), `raw_json` (copy c·ªßa to√†n b·ªô `_source`)
  - **Extraction Logic**:
    - Network fields: ∆Øu ti√™n `data.source.ip` / `data.destination.ip`, fallback `srcip` / `agent.ip`
    - Flow stats: T·ª´ `data.flow.*` ho·∫∑c `suricata.eve.flow.*`
    - HTTP: T·ª´ `data.http.*` ho·∫∑c `suricata.eve.http.*`
    - Suricata: T·ª´ `data.suricata.*` ho·∫∑c `suricata.eve.alert.*`
  - **Default Values**: T·∫•t c·∫£ field kh√¥ng t·ªìn t·∫°i ‚Üí `None` ho·∫∑c `{}` (kh√¥ng crash)

- **`_build_indexer_query(cursor, agent_id=None) ‚Üí Dict`**
  - **Purpose**: X√¢y d·ª±ng OpenSearch query v·ªõi SOC two-tier filtering
  - **Query Structure**:
    ```json
    {
      "size": WAZUH_PAGE_LIMIT (default 200),
      "sort": [{"@timestamp": "asc"}, {"agent.id": "asc"}, {"_id": "asc"}],
      "query": {
        "bool": {
          "filter": [
            {
              "bool": {
                "should": [
                  {
                    "bool": {
                      "must": [
                        {"range": {"rule.level": {"gte": MIN_LEVEL, "lte": MAX_LEVEL}}},
                        {"bool": {"should": rule_id_filters, "minimum_should_match": 1}}
                      ]
                    }
                  },
                  {"range": {"rule.level": {"gte": ALWAYS_REEVALUATE_LEVEL_GTE}}}
                ],
                "minimum_should_match": 1
              }
            },
            {"range": {"@timestamp": {"gt": cutoff_iso}}},
            {"term": {"agent.id": agent_id}}  // N·∫øu agent_id ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
          ]
        }
      },
      "search_after": [timestamp, agent_id, _id]  // N·∫øu c√≥ cursor.sort
    }
    ```

#### 1.2 State Management

- **Cursor File** (`CURSOR_PATH`, default `/app/state/cursor.json`):
  - Format: `{"timestamp": "2025-01-XX...", "sort": [timestamp, agent_id, _id]}`
  - Purpose: Track last processed alert ƒë·ªÉ tr√°nh duplicate v√† ƒë·∫£m b·∫£o sequential processing
  - Persistence: `_save_cursor()` ghi sau m·ªói batch, `_load_cursor()` ƒë·ªçc khi kh·ªüi ƒë·ªông

---

### 2. Analyzer Module (`src/analyzer/`)

#### 2.1 Heuristic Scoring (`src/analyzer/heuristic.py`)

**Function**: `score(alert: Dict) ‚Üí float (0.0-1.0)`

**Scoring Formula**:
```
base_score = _calculate_base_score(rule_level)
  - Level 0: 0.0
  - Level 1-11: Linear (level / 15.0)
  - Level 12-14: Non-linear curve (0.80 + normalized * 0.15)
  - Level 15: 1.0

group_bonus = _calculate_group_bonus(rule_groups)
  - CRITICAL_GROUPS (sql_injection, attack): +0.15
  - HIGH_GROUPS (bruteforce, web_attack, ids): +0.10
  - MEDIUM_GROUPS (web, invalid_access): +0.05

multipliers:
  - SUCCESSFUL_ATTACK_RULES (31106): x1.2
  - XSS_RULES (31105, 31154): x1.15
  - FREQUENCY_BASED_RULES (31151-31163): x1.1

flow_bonus:
  - pkts_toserver > 100: +0.05 (DoS indicator)
  - bytes_toserver > 10000: +0.03

http_bonus:
  - HTTP 200 (successful attack): +0.10
  - HTTP 404 (scanning): +0.02

action_bonus:
  - suricata.action == "allowed" (attack passed firewall): +0.10

final_score = min((base_score + group_bonus) * multipliers + flow_bonus + http_bonus + action_bonus, 1.0)
```

**Key Constants**:
- `CRITICAL_GROUPS`: `{"sql_injection", "sqlinjection", "attack"}`
- `HIGH_GROUPS`: `{"authentication_failed", "bruteforce", "web_attack", "web_scan", "recon", "ids", "suricata"}`
- `SUCCESSFUL_ATTACK_RULES`: `{"31106"}` (Web attack returned 200)
- `XSS_RULES`: `{"31105", "31154"}`

#### 2.2 LLM Analysis (`src/analyzer/llm.py`)

**Function**: `triage_llm(alert_text: str, rule_context: Dict) ‚Üí Dict`

**Input Processing**:
1. **Cache Check** (`LLM_CACHE_ENABLE=True`):
   - Key: `hash(alert_text + rule_context.id)`
   - TTL: `LLM_CACHE_TTL_SECONDS` (default 3600s)
   - Cache hit ‚Üí return cached result (kh√¥ng g·ªçi API)

2. **Prompt Construction**:
   - **System Prompt**: Role definition (SOC analyst), anti-hallucination rules
   - **Rule Context**: `rule.id`, `level`, `description`, `groups`, `mitre.ids`
   - **Rule-Specific Guidance**: 
     - Rule 31105 (XSS): "CRITICAL: XSS detection ‚Üí threat_level: high/critical, tags: [xss, web_attack]"
     - Rule 31103/31104 (SQLi): "CRITICAL: SQL injection ‚Üí threat_level: critical, tags: [sql_injection, web_attack]"
   - **Alert Text**: Redacted alert context (rule, HTTP, network, flow, Suricata, message, FP context, correlation)
   - **Output Schema**: JSON v·ªõi `threat_level`, `confidence`, `summary`, `tags`, `evidence`, `mitre`

3. **API Call**:
   - Endpoint: `{OPENAI_API_BASE}/chat/completions`
   - Model: `LLM_MODEL` (default `gpt-4o-mini`)
   - Temperature: Dynamic d·ª±a tr√™n `rule_level`:
     - Level >= 12: 0.2 (very precise)
     - Level >= 9: 0.25
     - Level >= 7: 0.3
     - Level < 7: 0.35 (more flexible)
   - Max tokens: `LLM_MAX_TOKENS` (default 512)
   - Timeout: `LLM_TIMEOUT_SEC` (default 20s)

4. **Response Parsing**:
   - Parse JSON t·ª´ `response.choices[0].message.content`
   - Validate: `threat_level` trong `ALLOWED_THREAT_LEVELS`, `tags` trong `ALLOWED_TAGS`
   - Cache result n·∫øu `LLM_CACHE_ENABLE=True`

5. **Error Handling**:
   - API timeout ‚Üí return default `{"threat_level": "medium", "confidence": 0.0, "tags": []}`
   - JSON parse error ‚Üí log warning, return default
   - Rate limit ‚Üí log warning, return default

**Output Schema**:
```json
{
  "threat_level": "critical" | "high" | "medium" | "low" | "none",
  "confidence": 0.0-1.0,
  "summary": "Brief description of what happened, where, impact, evidence",
  "tags": ["sql_injection", "web_attack", ...],
  "evidence": ["field=value", ...],  // Optional
  "mitre": ["T1190", "T1059", ...]   // Optional
}
```

**Anti-Hallucination Rules** (enforced trong prompt):
- Kh√¥ng ƒë∆∞·ª£c "ch·∫ø" field/value kh√¥ng c√≥ trong alert
- N·∫øu thi·∫øu field ‚Üí ghi `"Not present in alert"` ho·∫∑c `"Unknown"`
- Evidence ph·∫£i l√† `field=value` v·ªõi field th·∫≠t s·ª± t·ªìn t·∫°i
- N·∫øu kh√¥ng ch·∫Øc ‚Üí gi·∫£m `confidence`, nh∆∞ng alert v·∫´n ƒë∆∞·ª£c chuy·ªÉn sang notify

#### 2.3 Triage Fusion (`src/analyzer/triage.py`)

**Function**: `run(alert: Dict) ‚Üí Dict`

**Pipeline Steps**:

1. **Enrichment** (`ENRICHMENT_ENABLE=True`):
   - `enrich_alert(alert)` ‚Üí th√™m `enrichment.{geoip, threat_intel}` v√†o alert
   - GeoIP: Country, region, city, ASN, org (t·ª´ ipapi.co, cached)
   - Threat Intel: (c√≥ th·ªÉ m·ªü r·ªông v·ªõi VirusTotal, AbuseIPDB)

2. **Correlation** (`CORRELATION_ENABLE=True`):
   - `correlate_alert(alert)` ‚Üí th√™m `correlation.{is_correlated, group_key, group_size, first_seen, attack_pattern}` v√†o alert
   - Correlation engine (in-memory): Groups alerts theo `src_ip + attack_type`, `dst_ip + attack_type`, `signature_id`, `rule.id`
   - Time window: `LOOKBACK_MINUTES_CORRELATION` (default 30 minutes)

3. **FP Filtering**:
   - `analyze_fp_risk(alert, correlation_info)` ‚Üí th√™m `fp_filtering.{fp_risk, fp_reason, noise_signals}` v√†o alert
   - **Kh√¥ng drop**, ch·ªâ label: `fp_risk` = LOW/MEDIUM/HIGH
   - Checks: Internal IP + 404, benign signatures, repetition, cron patterns

4. **Heuristic Score**:
   - `heuristic_score(alert)` ‚Üí `h_score` (0.0-1.0)

5. **LLM Analysis**:
   - Build alert text (redacted) v·ªõi rule context, HTTP, network, flow, Suricata, FP context, correlation
   - `triage_llm(alert_text, rule_context)` ‚Üí `llm_result`
   - Extract: `threat_level`, `confidence`, `summary`, `tags`

6. **Confidence Boost** (n·∫øu LLM nh·∫≠n ƒë√∫ng):
   - Rule 31105 + tag "xss" ‚Üí `confidence += 0.15`
   - Rule 31103/31104 + tag "sql_injection" ‚Üí `confidence += 0.20`
   - Rule 100144/100145/100146 + tag "command_injection" ‚Üí `confidence += 0.20`

7. **Dynamic Weighting**:
   - N·∫øu `llm_confidence < 0.3`: `effective_h_weight = min(HEURISTIC_WEIGHT + 0.2, 0.9)`, `effective_l_weight = max(LLM_WEIGHT - 0.2, 0.1)`
   - N·∫øu `llm_confidence > 0.8`: `effective_h_weight = max(HEURISTIC_WEIGHT - 0.1, 0.3)`, `effective_l_weight = min(LLM_WEIGHT + 0.1, 0.7)`
   - Ng∆∞·ª£c l·∫°i: d√πng `HEURISTIC_WEIGHT` v√† `LLM_WEIGHT` m·∫∑c ƒë·ªãnh

8. **Score Fusion**:
   ```
   fused_score = (effective_h_weight * h_score) + (effective_l_weight * llm_confidence)
   ```

9. **Threat Level Adjustment**:
   ```
   threat_adjustment = THREAT_LEVEL_ADJUSTMENTS[threat_level]
     - "critical": +0.10
     - "high": +0.05
     - "medium": 0.0
     - "low": -0.05
     - "none": -0.10
   
   final_score = fused_score + threat_adjustment
   final_score = clamp(final_score, 0.0, 1.0)
   ```

10. **Alert Card Formatting**:
    - `format_alert_card(alert, triage_result)` ‚Üí `alert_card` (title, short summary, fields)

**Output**:
```python
{
    "title": "Alert title from alert_card",
    "score": final_score (0.0-1.0),
    "threat_level": threat_level,
    "summary": llm_result["summary"],
    "tags": llm_result["tags"],
    "heuristic_score": h_score,
    "llm_confidence": llm_confidence,
    "llm_threat_level": threat_level,
    "alert_card": alert_card,
    "alert_card_short": alert_card_short
}
```

---

### 3. Orchestrator Module (`src/orchestrator/notify.py`)

**Function**: `notify(alert: Dict, triage: Dict) ‚Üí None`

**Pipeline Steps**:

1. **Critical Override Check** (`should_notify_critical_attack`):
   - **Rule-based**: `rule.id` trong `CRITICAL_ATTACK_RULES` ‚Üí `override=True`
   - **Tag-based**: `tags` ch·ª©a `CRITICAL_ATTACK_TAGS` ‚Üí `override=True`
   - **Level-based**: `rule.level >= 12` ‚Üí `override=True`
   - **Suricata severity**: `suricata_severity >= 3` + `action == "allowed"` ‚Üí `override=True`
   - **Attack tools**: User agent ch·ª©a `sqlmap`, `nmap`, `burp`, ... ‚Üí `override=True`
   - **Correlation**: `correlation.group_size >= 5` ‚Üí `override=True`
   - **Threat level**: `threat_level in ["critical", "high"]` + `confidence > 0.3` ‚Üí `override=True`

2. **Score Threshold Check**:
   - N·∫øu `override=True` ‚Üí lu√¥n notify
   - N·∫øu `override=False` ‚Üí ch·ªâ notify n·∫øu `triage.score >= TRIAGE_THRESHOLD` (default 0.70)

3. **Message Formatting** (`_format_telegram_message`):
   - **15 Sections**:
     1. **Header**: ENV name, timestamp (local), event_id, index
     2. **Scores**: Heuristic, LLM confidence, final score, threat level, FP risk
     3. **Identity**: Agent/host, user, process (n·∫øu c√≥)
     4. **Network Summary**: Src/dst IP/Port, proto, app_proto, direction (WAN/DMZ/LAN)
     5. **HTTP Context**: URL, method, status, hostname, user-agent, referer
     6. **Flow Statistics**: Packets/bytes to server/client
     7. **Suricata Alert**: Signature, category, action (allowed/blocked)
     8. **What Happened**: LLM summary
     9. **Evidence**: List `field=value` (d√πng `_to_int` ƒë·ªÉ convert s·ªë)
     10. **IOCs**: IPs, domains, hashes
     11. **Correlation**: Group size, first_seen/last_seen, attack pattern
     12. **Recommended Actions**: Block IP, isolate host, collect memory, check WAF
     13. **MITRE ATT&CK**: TTPs t·ª´ rule.mitre ho·∫∑c LLM
     14. **Kibana Query**: Link + query string ƒë·ªÉ analyst xem log
     15. **Tags**: T·ª´ triage.tags
   - **Markdown Formatting**: Bold (`*text*`), italic (`_text_`), code (`\`text\``)
   - **Escape Special Chars**: `_escape_markdown_content()` ƒë·ªÉ tr√°nh parse error

4. **Message Validation** (`_validate_telegram_message`):
   - Length check: Max 4096 chars (Telegram limit)
   - Balanced asterisks (Markdown formatting)
   - Unescaped parentheses/brackets check

5. **Send to Telegram**:
   - Endpoint: `https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage`
   - Payload: `{"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown"}`
   - **Retry Logic**: `RetrySession` (max 3 retries, exponential backoff)
   - **Fallback**: N·∫øu Markdown parse error ‚Üí g·ª≠i l·∫°i v·ªõi `parse_mode=None` (plain text)

6. **Error Handling**:
   - Format error ‚Üí log error, g·ª≠i fallback message (simplified format)
   - Telegram API error ‚Üí log error, retry (kh√¥ng crash pipeline)

**Helper Functions**:

- **`_to_int(value: Any) ‚Üí Optional[int]`**:
  - Convert string/int/float ‚Üí int
  - Handles: `"120"` ‚Üí `120`, `120.5` ‚Üí `120`, `None` ‚Üí `None`
  - Used trong evidence/flow stats ƒë·ªÉ tr√°nh `TypeError: '>' not supported between 'str' and 'int'`

---

### 4. Common Utilities (`src/common/`)

#### 4.1 Correlation Engine (`src/common/correlation.py`)

**Class**: `AlertCorrelationEngine`

**State**:
- `self.alert_groups: Dict[str, List[Dict]]` - Group key ‚Üí list of alerts
- `self.group_metadata: Dict[str, Dict]` - Group key ‚Üí metadata (first_seen, last_seen, count, attack_pattern)
- `self.time_window_minutes: int` - Correlation window (default 15, configurable via `LOOKBACK_MINUTES_CORRELATION`)

**Methods**:

- **`correlate(alert) ‚Üí Dict`**:
  - Generate group keys theo priority:
    1. `source_attack`: `src:{src_ip}:attack:{attack_type}`
    2. `destination_attack`: `dst:{dst_ip}:attack:{attack_type}`
    3. `signature`: `sig:{signature_id}`
    4. `rule_pattern`: `rule:{rule_id}`
  - Check time window: N·∫øu alert trong window c·ªßa existing group ‚Üí add v√†o group
  - N·∫øu kh√¥ng ‚Üí create new group
  - Return: `{is_correlated, group_key, group_size, first_seen, last_seen, attack_pattern, correlation_type}`

- **`_cleanup_old_groups()`**:
  - Ch·∫°y m·ªói 1 gi·ªù (ho·∫∑c khi correlate ƒë∆∞·ª£c g·ªçi)
  - Remove groups c≈© h∆°n 2 gi·ªù

**Global Instance**: `correlation_engine = AlertCorrelationEngine()` (singleton)

**Function**: `correlate_alert(alert) ‚Üí Dict` (wrapper g·ªçi `correlation_engine.correlate(alert)`)

#### 4.2 FP Filtering (`src/common/fp_filtering.py`)

**Function**: `analyze_fp_risk(alert, correlation_info) ‚Üí Dict`

**Checks**:

1. **Internal IP + HTTP 404**:
   - `src_ip` l√† internal (RFC 1918) **AND** `http.status == "404"` ‚Üí `fp_reason.append("Internal IP with HTTP 404")`, `noise_signals.append("internal_scan_404")`

2. **Benign Signatures**:
   - `suricata_alert.signature` ch·ª©a `"health-check"`, `"monitoring"`, `"keepalive"`, ... ‚Üí `fp_reason.append("Benign signature pattern")`

3. **Benign User Agents**:
   - `http.user_agent` ch·ª©a `"healthcheck"`, `"monitoring"`, `"pingdom"`, ... ‚Üí `fp_reason.append("Benign user agent")`

4. **Repetition**:
   - N·∫øu `correlation_info.group_size >= 10` ‚Üí `fp_reason.append("High repetition")`, `fp_risk = HIGH`
   - N·∫øu `correlation_info.group_size >= 5` ‚Üí `fp_reason.append("Moderate repetition")`, `fp_risk = MEDIUM`

5. **Cron/Job Patterns**:
   - `message` ch·ª©a `"cron"`, `"scheduled task"`, `"job"` ‚Üí `fp_reason.append("Cron/job pattern")`

**FP Risk Calculation**:
- `fp_reasons >= 3` ho·∫∑c `high_repetition` ‚Üí `fp_risk = HIGH`
- `fp_reasons >= 2` ho·∫∑c `moderate_repetition` ‚Üí `fp_risk = MEDIUM`
- `fp_reasons >= 1` ‚Üí `fp_risk = LOW`
- Ng∆∞·ª£c l·∫°i ‚Üí `fp_risk = LOW`

**Output**:
```python
{
    "fp_risk": "LOW" | "MEDIUM" | "HIGH",
    "fp_reason": ["reason1", "reason2", ...],
    "allowlist_hit": False,  # Future: whitelist support
    "noise_signals": ["internal_scan_404", "benign_signature_health-check", ...]
}
```

#### 4.3 Enrichment (`src/common/enrichment.py`)

**Class**: `GeoIPEnricher`

**Methods**:

- **`enrich(ip: str) ‚Üí Dict`**:
  - Skip private IPs ‚Üí return `{is_internal: True, country: "Internal"}`
  - Check cache (TTL 1 hour)
  - Call `ipapi.co/{ip}/json/` (free, no API key)
  - Cache result
  - Return: `{country, country_code, region, city, latitude, longitude, asn, org, timezone, is_internal}`

**Function**: `enrich_alert(alert) ‚Üí Dict` (wrapper g·ªçi `GeoIPEnricher().enrich(src_ip)`)

#### 4.4 LLM Cache (`src/common/llm_cache.py`)

**Class**: `LLMCache`

**State**:
- `self._cache: Dict[str, Tuple[Dict, float]]` - Key ‚Üí (result, cached_at timestamp)
- `self._max_size: int` - Max cache entries (default 1000)
- `self._ttl: int` - TTL seconds (default 3600)

**Methods**:

- **`get(alert_text, rule_context) ‚Üí Optional[Dict]`**:
  - Key: `hash(alert_text + rule_context.id)`
  - Check TTL: N·∫øu `now - cached_at < ttl` ‚Üí return cached result
  - Ng∆∞·ª£c l·∫°i ‚Üí return None

- **`set(alert_text, rule_context, result)`**:
  - Key: `hash(alert_text + rule_context.id)`
  - Store: `(result, time.time())`
  - Evict oldest n·∫øu `len(cache) > max_size`

**Global Instance**: `_llm_cache = LLMCache()` (singleton)

**Functions**: `get_llm_cache() ‚Üí LLMCache`, `clear_llm_cache()`

#### 4.5 Retry Session (`src/common/web.py`)

**Class**: `RetrySession` (extends `requests.Session`)

**Configuration**:
- `max_retries: int` (default 3)
- `backoff_factor: float` (default 0.5)
- `timeout: int` (default 10s)

**Retry Logic**:
- Retry tr√™n: `ConnectionError`, `Timeout`, `HTTPError` (5xx, 429)
- Exponential backoff: `sleep = backoff_factor * (2 ** retry_count)`
- Max retries: 3

**Usage**: D√πng cho t·∫•t c·∫£ HTTP calls (Wazuh API, Indexer, OpenAI API, Telegram API, GeoIP API)

#### 4.6 Redaction (`src/common/redaction.py`)

**Class**: `Redactor`

**Methods**:

- **`redact(text: str) ‚Üí Tuple[str, List[str]]`**:
  - Redact PII: IPs (gi·ªØ 2 octets ƒë·∫ßu), emails, credit cards, SSNs
  - Return: `(redacted_text, redacted_items)`

**Usage**: Redact alert text tr∆∞·ªõc khi g·ª≠i cho LLM (privacy compliance)

#### 4.7 Deduplication (`src/common/dedup.py`)

**Function**: `dedup_key(alert) ‚Üí str`

**Key Format**: `SHA256(rule_id:agent_id:srcip:YYYY-MM-DD)[:16]`

**Purpose**: Generate deterministic key ƒë·ªÉ deduplicate alerts trong c√πng ng√†y (local timezone)

**Usage**: (Hi·ªán t·∫°i ch∆∞a ƒë∆∞·ª£c d√πng trong pipeline ch√≠nh, c√≥ th·ªÉ t√≠ch h·ª£p v√†o notify ƒë·ªÉ tr√°nh spam)

---

## üîÑ DATA FLOW & STATE MANAGEMENT

### Data Flow Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Wazuh Indexer (OpenSearch)                   ‚îÇ
‚îÇ                    Index: wazuh-alerts-*                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ HTTP POST /_search
                             ‚îÇ Query: SOC two-tier filter + cursor
                             ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   WazuhClient.fetch_alerts()                     ‚îÇ
                ‚îÇ   - Load cursor from file                        ‚îÇ
                ‚îÇ   - Build query (two-tier filter)                ‚îÇ
                ‚îÇ   - Fetch batch (page_size=200)                  ‚îÇ
                ‚îÇ   - Normalize each alert                        ‚îÇ
                ‚îÇ   - Update & save cursor                        ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ List[AlertNormalized]
                             ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   For each alert:                                ‚îÇ
                ‚îÇ   1. enrich_alert()                             ‚îÇ
                ‚îÇ      ‚Üí alert["enrichment"]                       ‚îÇ
                ‚îÇ   2. correlate_alert()                          ‚îÇ
                ‚îÇ      ‚Üí alert["correlation"]                     ‚îÇ
                ‚îÇ   3. analyze_fp_risk()                          ‚îÇ
                ‚îÇ      ‚Üí alert["fp_filtering"]                    ‚îÇ
                ‚îÇ   4. run_triage()                               ‚îÇ
                ‚îÇ      ‚Üí triage_result                            ‚îÇ
                ‚îÇ   5. notify()                                   ‚îÇ
                ‚îÇ      ‚Üí Telegram (if score >= threshold OR critical)
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### State Management

#### 1. Cursor State (File-based)

**Location**: `CURSOR_PATH` (default `/app/state/cursor.json`)

**Format**:
```json
{
  "timestamp": "2025-01-XXT10:30:45.123Z",
  "sort": [1705312245123, "001", "abc123def456"]
}
```

**Lifecycle**:
- **Load**: Khi `WazuhClient.__init__()` ho·∫∑c `fetch_alerts()` ƒë∆∞·ª£c g·ªçi l·∫ßn ƒë·∫ßu
- **Update**: Sau m·ªói batch fetch, update v·ªõi timestamp v√† sort values c·ªßa alert cu·ªëi c√πng
- **Save**: `_save_cursor()` ghi v√†o file (sync, blocking I/O)

**Purpose**:
- **Sequential Processing**: ƒê·∫£m b·∫£o alerts ƒë∆∞·ª£c x·ª≠ l√Ω theo th·ª© t·ª± th·ªùi gian
- **No Duplicates**: `search_after` cursor ƒë·∫£m b·∫£o kh√¥ng fetch l·∫°i alerts ƒë√£ x·ª≠ l√Ω
- **Resume After Restart**: Pipeline c√≥ th·ªÉ restart v√† ti·∫øp t·ª•c t·ª´ cursor cu·ªëi c√πng

**Edge Cases**:
- **No cursor file**: Fetch t·ª´ `now - 24h` (ho·∫∑c `WAZUH_LOOKBACK_MINUTES` trong realtime mode)
- **Corrupted cursor**: Log warning, fallback v·ªÅ time-based cutoff
- **Very old cursor**: D√πng `max(cursor.timestamp, now - 24h)` ƒë·ªÉ tr√°nh fetch qu√° nhi·ªÅu alerts

#### 2. Correlation State (In-Memory)

**Storage**: `AlertCorrelationEngine.alert_groups` v√† `self.group_metadata`

**Lifecycle**:
- **Initialize**: Khi `correlation_engine = AlertCorrelationEngine()` ƒë∆∞·ª£c t·∫°o (singleton, global)
- **Update**: M·ªói khi `correlate_alert()` ƒë∆∞·ª£c g·ªçi
- **Cleanup**: T·ª± ƒë·ªông cleanup groups c≈© h∆°n 2 gi·ªù (m·ªói 1 gi·ªù check m·ªôt l·∫ßn)

**Persistence**: **Kh√¥ng persist** (in-memory only)

**Impact**:
- **Restart**: Correlation groups b·ªã m·∫•t khi pipeline restart
- **Scale**: N·∫øu ch·∫°y nhi·ªÅu instance ‚Üí m·ªói instance c√≥ correlation state ri√™ng (kh√¥ng share)

**Future Improvement**: C√≥ th·ªÉ persist v√†o Redis/DB ƒë·ªÉ share gi·ªØa instances

#### 3. LLM Cache State (In-Memory)

**Storage**: `LLMCache._cache` (Dict)

**Lifecycle**:
- **Initialize**: Khi `_llm_cache = LLMCache()` ƒë∆∞·ª£c t·∫°o (singleton)
- **Update**: M·ªói khi LLM API call th√†nh c√¥ng
- **Eviction**: LRU eviction khi `len(cache) > max_size` (default 1000)

**Persistence**: **Kh√¥ng persist** (in-memory only)

**Impact**:
- **Restart**: Cache b·ªã m·∫•t khi pipeline restart
- **Memory**: Max memory = `max_size * avg_result_size` (~100KB n·∫øu m·ªói result ~100 bytes)

**Future Improvement**: C√≥ th·ªÉ persist v√†o Redis ƒë·ªÉ share gi·ªØa instances v√† survive restarts

#### 4. Deduplication State (Not Currently Used)

**Storage**: (Ch∆∞a implement)

**Future**: C√≥ th·ªÉ d√πng `dedup_key()` ƒë·ªÉ track alerts ƒë√£ notify trong `DEDUP_WINDOW_MINUTES` (default 10 minutes)

---

## üõ°Ô∏è ERROR HANDLING & RESILIENCE

### Error Handling Strategy

**Principle**: **Never crash pipeline, always log errors, graceful degradation**

#### 1. Collector Errors

- **Indexer Connection Error**:
  - Log error v·ªõi context (component, action, error message)
  - Return empty list ‚Üí pipeline ti·∫øp t·ª•c (kh√¥ng crash)
  - Retry logic trong `RetrySession` (max 3 retries)

- **Query Syntax Error**:
  - Log error v·ªõi query payload
  - Return empty list ‚Üí pipeline ti·∫øp t·ª•c

- **Normalization Error**:
  - Log error v·ªõi alert `_id`
  - Skip alert (kh√¥ng normalize) ‚Üí ti·∫øp t·ª•c v·ªõi alert ti·∫øp theo
  - **Kh√¥ng crash pipeline**

#### 2. Analyzer Errors

- **Enrichment Error**:
  - Log debug (kh√¥ng log error v√¨ enrichment l√† optional)
  - Set `alert["enrichment"] = {}` ‚Üí ti·∫øp t·ª•c

- **Correlation Error**:
  - Log debug
  - Set `alert["correlation"] = {"is_correlated": False, "group_size": 1}` ‚Üí ti·∫øp t·ª•c

- **FP Filtering Error**:
  - Log debug
  - Set `alert["fp_filtering"] = {"fp_risk": "LOW", "fp_reason": []}` ‚Üí ti·∫øp t·ª•c

- **Heuristic Score Error**:
  - Log error
  - Return `h_score = 0.0` ‚Üí ti·∫øp t·ª•c (alert v·∫´n ƒë∆∞·ª£c x·ª≠ l√Ω)

- **LLM API Error**:
  - **Timeout**: Log warning, return default `{"threat_level": "medium", "confidence": 0.0}`
  - **Rate Limit**: Log warning, return default
  - **JSON Parse Error**: Log warning, return default
  - **API Key Missing**: Log warning, return default
  - **Pipeline ti·∫øp t·ª•c** (kh√¥ng crash)

#### 3. Orchestrator Errors

- **Message Formatting Error**:
  - Log error v·ªõi exception traceback
  - **Fallback**: G·ª≠i simplified message (kh√¥ng format Markdown) ‚Üí **kh√¥ng m·∫•t c·∫£nh b√°o**

- **Telegram API Error**:
  - **Markdown Parse Error**: Retry v·ªõi `parse_mode=None` (plain text)
  - **Rate Limit**: Retry v·ªõi exponential backoff (trong `RetrySession`)
  - **Connection Error**: Retry (max 3 l·∫ßn)
  - **N·∫øu v·∫´n fail**: Log error ‚Üí **kh√¥ng crash pipeline** (alert ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω, ch·ªâ fail ·ªü notification)

#### 4. State Persistence Errors

- **Cursor Save Error**:
  - Log error
  - **Pipeline ti·∫øp t·ª•c** (cursor s·∫Ω ƒë∆∞·ª£c save ·ªü l·∫ßn fetch ti·∫øp theo)

- **Cursor Load Error**:
  - Log warning
  - Fallback v·ªÅ time-based cutoff ‚Üí pipeline ti·∫øp t·ª•c

### Resilience Mechanisms

1. **Retry Logic**: T·∫•t c·∫£ HTTP calls d√πng `RetrySession` v·ªõi exponential backoff
2. **Fallback Messages**: N·∫øu formatting fail ‚Üí g·ª≠i simplified message
3. **Graceful Degradation**: N·∫øu LLM/enrichment fail ‚Üí pipeline v·∫´n ch·∫°y v·ªõi heuristic score
4. **No Silent Drops**: M·ªçi alert ƒë√£ qua filter ƒë·ªÅu ƒë∆∞·ª£c x·ª≠ l√Ω (kh√¥ng b·ªã drop ·ªü analyzer/orchestrator)

---

## ‚ö° PERFORMANCE & SCALABILITY

### Performance Characteristics

**Single-Threaded**: Pipeline ch·∫°y tr√™n m·ªôt thread (kh√¥ng c√≥ concurrency)

**Bottlenecks**:
1. **LLM API Calls**: M·ªói alert ‚Üí 1 API call (c√≥ th·ªÉ m·∫•t 1-5s)
2. **GeoIP API Calls**: M·ªói unique IP ‚Üí 1 API call (cached sau l·∫ßn ƒë·∫ßu)
3. **Indexer Query**: M·ªói poll ‚Üí 1 query (c√≥ th·ªÉ m·∫•t 100-500ms)

**Optimizations**:
1. **LLM Caching**: Cache k·∫øt qu·∫£ LLM (TTL 1h) ‚Üí gi·∫£m API calls cho duplicate alerts
2. **GeoIP Caching**: Cache GeoIP results (TTL 1h) ‚Üí gi·∫£m API calls cho duplicate IPs
3. **Batch Processing**: Fetch nhi·ªÅu alerts m·ªôt l√∫c (page_size=200) ‚Üí gi·∫£m s·ªë query
4. **Cursor Pagination**: D√πng `search_after` thay v√¨ offset ‚Üí nhanh h∆°n v·ªõi large datasets

### Scalability

**Vertical Scaling**: TƒÉng `WAZUH_PAGE_LIMIT` v√† `WAZUH_MAX_BATCHES` ƒë·ªÉ fetch nhi·ªÅu alerts h∆°n m·ªói poll

**Horizontal Scaling**: Ch·∫°y nhi·ªÅu instance v·ªõi:
- **Different agents**: M·ªói instance filter theo `agent.id` kh√°c nhau
- **Different time windows**: M·ªói instance d√πng cursor ri√™ng (kh√¥ng conflict)
- **Shared state**: (Future) D√πng Redis cho correlation/LLM cache ƒë·ªÉ share gi·ªØa instances

**Limitations**:
- **Correlation**: In-memory ‚Üí kh√¥ng share gi·ªØa instances
- **LLM Cache**: In-memory ‚Üí kh√¥ng share gi·ªØa instances
- **Single-threaded**: Kh√¥ng th·ªÉ parallelize processing trong m·ªôt instance

**Future Improvements**:
- **Async/Await**: D√πng `asyncio` ƒë·ªÉ parallelize LLM calls (n·∫øu c√≥ nhi·ªÅu alerts)
- **Message Queue**: D√πng RabbitMQ/Kafka ƒë·ªÉ decouple collector v√† analyzer
- **Distributed Correlation**: D√πng Redis ƒë·ªÉ share correlation state

---

## ‚öôÔ∏è CONFIGURATION MANAGEMENT

### Configuration Source

**Environment Variables** (loaded via `python-dotenv` t·ª´ `.env` file)

**Loading Order**:
1. `.env` file (n·∫øu c√≥)
2. System environment variables (override `.env`)

### Configuration Categories

#### 1. Wazuh Connection

- `WAZUH_API_URL`: Wazuh Manager API URL (default: `http://localhost:55000`)
- `WAZUH_API_USER`: API username (default: `wazuh`)
- `WAZUH_API_PASS`: API password
- `WAZUH_API_TOKEN`: Bearer token (preferred over user/pass)
- `WAZUH_API_VERIFY_SSL`: SSL verification (True/False or cert file path)
- `WAZUH_INDEXER_URL`: Wazuh Indexer URL (OpenSearch)
- `WAZUH_INDEXER_USER`: Indexer username
- `WAZUH_INDEXER_PASS`: Indexer password
- `WAZUH_INDEXER_VERIFY_SSL`: SSL verification
- `WAZUH_ALERTS_INDEX`: Index pattern (default: `wazuh-alerts-*`)

#### 2. SOC Filtering

- `MIN_LEVEL`: Minimum rule level for Tier 1 (default: 3)
- `MAX_LEVEL`: Maximum rule level for Tier 1 (default: 7)
- `INCLUDE_RULE_IDS`: Comma-separated rule IDs (default: `"100100"`)
- `INCLUDE_RULE_ID_PREFIX`: Rule ID prefix (default: `"1001"`)
- `ALWAYS_REEVALUATE_LEVEL_GTE`: Always include level >= this (default: 7)

#### 3. Polling & Timing

- `WAZUH_POLL_INTERVAL_SEC`: Poll interval in seconds (default: 8)
- `WAZUH_REALTIME_MODE`: Enable real-time mode (default: False)
- `WAZUH_REALTIME_INTERVAL_SEC`: Real-time poll interval (default: 1.0)
- `WAZUH_LOOKBACK_MINUTES`: Lookback window for real-time mode (default: 10)
- `WAZUH_DEMO_MODE`: Demo mode (ignore cursor, use lookback) (default: False)
- `WAZUH_START_FROM_NOW`: Start from now instead of cursor (default: False)
- `WAZUH_PAGE_LIMIT`: Page size for indexer query (default: 200)
- `WAZUH_MAX_BATCHES`: Max batches per poll (default: 5)

#### 4. Correlation & Dedup

- `CORRELATION_ENABLE`: Enable correlation (default: True)
- `LOOKBACK_MINUTES_CORRELATION`: Correlation time window (default: 30)
- `DEDUP_WINDOW_MINUTES`: Deduplication window (default: 10)

#### 5. Enrichment

- `ENRICHMENT_ENABLE`: Enable enrichment (default: True)
- `GEOIP_ENABLE`: Enable GeoIP (default: True)

#### 6. LLM

- `LLM_ENABLE`: Enable LLM analysis (default: False)
- `OPENAI_API_BASE`: OpenAI API base URL (default: `https://api.openai.com/v1`)
- `OPENAI_API_KEY`: OpenAI API key
- `LLM_MODEL`: Model name (default: `gpt-4o-mini`)
- `LLM_MAX_TOKENS`: Max tokens (default: 512)
- `LLM_TIMEOUT_SEC`: Timeout seconds (default: 20)
- `LLM_CACHE_ENABLE`: Enable LLM cache (default: True)
- `LLM_CACHE_TTL_SECONDS`: Cache TTL (default: 3600)
- `LLM_CACHE_MAX_SIZE`: Max cache entries (default: 1000)

#### 7. Triage

- `TRIAGE_THRESHOLD`: Score threshold for notification (default: 0.70)
- `HEURISTIC_WEIGHT`: Heuristic weight in fusion (default: 0.6)
- `LLM_WEIGHT`: LLM weight in fusion (default: 0.4)

#### 8. Notification

- `TELEGRAM_BOT_TOKEN`: Telegram bot token
- `TELEGRAM_CHAT_ID`: Telegram chat ID

#### 9. General

- `ENV_NAME`: Environment name (default: `dev`)
- `LOG_LEVEL`: Logging level (default: `INFO`)
- `LOCAL_TIMEZONE`: Local timezone (default: `Asia/Ho_Chi_Minh`)
- `CURSOR_PATH`: Cursor file path (default: `/app/state/cursor.json`)

### Configuration Validation

**At Startup**:
- Validate Wazuh auth: Either `WAZUH_API_TOKEN` or both `WAZUH_API_USER` and `WAZUH_API_PASS` must be set
- Validate Indexer auth: Both `WAZUH_INDEXER_USER` and `WAZUH_INDEXER_PASS` must be set
- Validate Triage weights: `HEURISTIC_WEIGHT + LLM_WEIGHT == 1.0` (allow small floating point errors)

**Runtime**:
- Log warnings n·∫øu config kh√¥ng h·ª£p l√Ω (vd: `LLM_ENABLE=True` nh∆∞ng `OPENAI_API_KEY` kh√¥ng set)

---

## üîó DEPENDENCIES & INTEGRATION POINTS

### External Dependencies

1. **Wazuh Indexer (OpenSearch)**:
   - Protocol: HTTP/HTTPS
   - Endpoint: `{WAZUH_INDEXER_URL}/{WAZUH_ALERTS_INDEX}/_search`
   - Auth: HTTP Basic Auth
   - Purpose: Source of truth cho alerts

2. **Wazuh Manager API** (Optional):
   - Protocol: HTTP/HTTPS
   - Endpoint: `{WAZUH_API_URL}/security/user/authenticate`
   - Auth: Bearer token ho·∫∑c Basic Auth
   - Purpose: Token refresh (n·∫øu d√πng token auth)

3. **OpenAI API**:
   - Protocol: HTTPS
   - Endpoint: `{OPENAI_API_BASE}/chat/completions`
   - Auth: Bearer token (`Authorization: Bearer {OPENAI_API_KEY}`)
   - Purpose: LLM analysis

4. **Telegram Bot API**:
   - Protocol: HTTPS
   - Endpoint: `https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage`
   - Auth: Token trong URL
   - Purpose: Notification delivery

5. **GeoIP API (ipapi.co)**:
   - Protocol: HTTPS
   - Endpoint: `https://ipapi.co/{ip}/json/`
   - Auth: None (free tier)
   - Purpose: IP geolocation

### Internal Dependencies

**Module Dependencies**:
```
run_pipeline.py
  ‚îú‚îÄ‚îÄ wazuh_client (collector)
  ‚îÇ     ‚îî‚îÄ‚îÄ RetrySession (common/web)
  ‚îú‚îÄ‚îÄ run_triage (analyzer/triage)
  ‚îÇ     ‚îú‚îÄ‚îÄ heuristic_score (analyzer/heuristic)
  ‚îÇ     ‚îú‚îÄ‚îÄ triage_llm (analyzer/llm)
  ‚îÇ     ‚îÇ     ‚îî‚îÄ‚îÄ LLMCache (common/llm_cache)
  ‚îÇ     ‚îú‚îÄ‚îÄ enrich_alert (common/enrichment)
  ‚îÇ     ‚îÇ     ‚îî‚îÄ‚îÄ RetrySession (common/web)
  ‚îÇ     ‚îú‚îÄ‚îÄ correlate_alert (common/correlation)
  ‚îÇ     ‚îú‚îÄ‚îÄ analyze_fp_risk (common/fp_filtering)
  ‚îÇ     ‚îî‚îÄ‚îÄ Redactor (common/redaction)
  ‚îî‚îÄ‚îÄ notify (orchestrator/notify)
        ‚îú‚îÄ‚îÄ format_alert_card (common/alert_formatter)
        ‚îî‚îÄ‚îÄ RetrySession (common/web)
```

**Shared State**:
- `correlation_engine` (singleton trong `correlation.py`)
- `_llm_cache` (singleton trong `llm_cache.py`)
- `GeoIPEnricher` (instance trong `enrichment.py`, c√≥ internal cache)

---

## üìä MONITORING & OBSERVABILITY

### Structured Logging

**Format**: JSON logs v·ªõi context fields

**Context Fields**:
- `component`: Module name (vd: `"wazuh_client"`, `"triage"`, `"llm"`, `"notify"`)
- `action`: Action name (vd: `"fetch_alerts"`, `"correlate"`, `"llm_analysis"`, `"send_telegram"`)
- `rule_id`: Rule ID (n·∫øu c√≥)
- `agent_id`: Agent ID (n·∫øu c√≥)
- `agent_name`: Agent name (n·∫øu c√≥)
- `score`: Triage score (n·∫øu c√≥)
- `threat_level`: Threat level (n·∫øu c√≥)

**Log Levels**:
- `DEBUG`: Detailed information (correlation details, cache hits, etc.)
- `INFO`: Important events (pipeline start, alerts processed, notifications sent)
- `WARNING`: Non-critical errors (LLM API key missing, GeoIP lookup failed)
- `ERROR`: Critical errors (indexer connection failed, normalization error)

**Example Log Entry**:
```json
{
  "timestamp": "2025-01-XXT10:30:45.123Z",
  "level": "INFO",
  "component": "triage",
  "action": "analysis_complete",
  "rule_id": "31105",
  "rule_level": 7,
  "agent_name": "webserver-001",
  "agent_id": "001",
  "score": 0.85,
  "threat_level": "high",
  "heuristic_score": 0.75,
  "llm_confidence": 0.90,
  "llm_tags": ["xss", "web_attack"],
  "message": "Triage analysis completed"
}
```

### Metrics (Future)

**Potential Metrics**:
- Alerts processed per minute
- Average processing time per alert
- LLM API latency (p50, p95, p99)
- Telegram notification success rate
- Correlation group sizes
- FP risk distribution (LOW/MEDIUM/HIGH)

**Implementation**: C√≥ th·ªÉ t√≠ch h·ª£p Prometheus metrics exporter

---

## üéØ SUMMARY

Pipeline n√†y l√† m·ªôt **single-threaded, event-driven loop** v·ªõi c√°c ƒë·∫∑c ƒëi·ªÉm:

1. **SOC-Grade Filtering**: Two-tier filtering ƒë·∫£m b·∫£o kh√¥ng b·ªè s√≥t c·∫£nh b√°o quan tr·ªçng
2. **Resilient**: Retry logic, fallback messages, graceful degradation
3. **Observable**: Structured logging v·ªõi context
4. **Configurable**: T·∫•t c·∫£ behavior ƒëi·ªÅu khi·ªÉn qua environment variables
5. **No Silent Drops**: M·ªçi alert ƒë√£ qua filter ƒë·ªÅu ƒë∆∞·ª£c x·ª≠ l√Ω v√† notify n·∫øu c·∫ßn

**Architecture Highlights**:
- **Collector**: SOC two-tier filtering, normalization, agent-balanced fetching
- **Analyzer**: Heuristic + LLM fusion v·ªõi dynamic weighting
- **Orchestrator**: Critical override, SOC-grade Telegram formatting
- **Common**: Correlation, FP labeling, enrichment, caching, retry logic

**Scalability**: Vertical scaling (tƒÉng page size) ho·∫∑c horizontal scaling (nhi·ªÅu instances v·ªõi cursor ri√™ng)

**Future Improvements**: Async processing, message queue, distributed state (Redis)

